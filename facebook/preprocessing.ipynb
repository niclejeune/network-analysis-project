{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T14:16:42.880165Z",
     "start_time": "2024-11-05T14:16:41.610005Z"
    }
   },
   "cell_type": "code",
   "source": "pip install networkx",
   "id": "d719589d5d9ae80d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\nicol\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T14:17:10.297651Z",
     "start_time": "2024-11-05T14:17:09.865547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# 1. Data Loading and Parsing Functions\n",
    "\n",
    "def load_edges(filename: str) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Reads the edges from the nodeId.edges file and returns a list of tuples representing each edge.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the edges file.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples where each tuple represents an edge (source, target).\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 2:\n",
    "                    source, target = map(int, parts)\n",
    "                    edges.append((source, target))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {filename} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading edges: {e}\")\n",
    "    return edges\n",
    "\n",
    "def load_circles(filename: str) -> Dict[str, List[int]]:\n",
    "    \"\"\"\n",
    "    Reads the circles from the nodeId.circles file and returns a dictionary with circle names as keys\n",
    "    and lists of node IDs as values.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the circles file.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary mapping circle names to lists of node IDs.\n",
    "    \"\"\"\n",
    "    circles = {}\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 2:\n",
    "                    circle_name = parts[0]\n",
    "                    node_ids = list(map(int, parts[1:]))\n",
    "                    circles[circle_name] = node_ids\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {filename} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading circles: {e}\")\n",
    "    return circles\n",
    "\n",
    "def load_features(filename: str) -> Dict[int, List[int]]:\n",
    "    \"\"\"\n",
    "    Reads the node features from the nodeId.feat file and returns a dictionary where each node ID\n",
    "    maps to a list of binary features.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the features file.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary mapping node IDs to their feature vectors.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 2:\n",
    "                    node_id = int(parts[0])\n",
    "                    feature_vector = list(map(int, parts[1:]))\n",
    "                    features[node_id] = feature_vector\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {filename} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading features: {e}\")\n",
    "    return features\n",
    "\n",
    "def load_ego_features(filename: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Reads the features of the ego node from nodeId.egofeat and returns a list of binary features\n",
    "    for the ego node.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the ego features file.\n",
    "\n",
    "    Returns:\n",
    "    - List of binary features for the ego node.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                features = list(map(int, line.strip().split()))\n",
    "                return features  # Assuming only one line exists\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {filename} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading ego features: {e}\")\n",
    "    return []\n",
    "\n",
    "def load_feature_names(filename: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Reads the feature names from nodeId.featnames and returns a list of anonymized feature names.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the feature names file.\n",
    "\n",
    "    Returns:\n",
    "    - List of feature names.\n",
    "    \"\"\"\n",
    "    feature_names = []\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                name = line.strip()\n",
    "                if name:\n",
    "                    feature_names.append(name)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {filename} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading feature names: {e}\")\n",
    "    return feature_names\n",
    "\n",
    "# 2. Graph Construction Functions\n",
    "\n",
    "def construct_graph(edges: List[Tuple[int, int]], ego_node: int) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Builds the graph using NetworkX, including the ego node connected to all nodes in the edges list.\n",
    "\n",
    "    Parameters:\n",
    "    - edges: List of tuples representing edges (source, target).\n",
    "    - ego_node: The ID of the ego node.\n",
    "\n",
    "    Returns:\n",
    "    - A NetworkX graph with the ego node and all edges.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    G.add_node(ego_node, label='ego')  # Labeling the ego node if needed\n",
    "    G.add_edges_from(edges)\n",
    "    return G\n",
    "\n",
    "def add_circles_to_graph(graph: nx.Graph, circles: Dict[str, List[int]]) -> None:\n",
    "    \"\"\"\n",
    "    Adds circle information as node attributes for further community analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: The NetworkX graph to which circle information will be added.\n",
    "    - circles: Dictionary mapping circle names to lists of node IDs.\n",
    "\n",
    "    Returns:\n",
    "    - None. The graph is modified in place.\n",
    "    \"\"\"\n",
    "    for circle_name, node_ids in circles.items():\n",
    "        for node_id in node_ids:\n",
    "            if node_id in graph.nodes:\n",
    "                if 'circles' in graph.nodes[node_id]:\n",
    "                    graph.nodes[node_id]['circles'].append(circle_name)\n",
    "                else:\n",
    "                    graph.nodes[node_id]['circles'] = [circle_name]\n",
    "            else:\n",
    "                # Optionally, add the node if it doesn't exist\n",
    "                graph.add_node(node_id, circles=[circle_name])\n",
    "    # Optionally, handle the ego node if it's part of any circle\n",
    "\n",
    "# 3. Network Metric Calculation Functions\n",
    "\n",
    "def calculate_degree(graph: nx.Graph) -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Calculates the degree for each node and returns a dictionary mapping node IDs to their degree values.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: The NetworkX graph.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary mapping node IDs to their degree.\n",
    "    \"\"\"\n",
    "    return dict(graph.degree())\n",
    "\n",
    "def calculate_clustering_coefficient(graph: nx.Graph) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Computes the clustering coefficient for each node.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: The NetworkX graph.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary mapping node IDs to their clustering coefficient.\n",
    "    \"\"\"\n",
    "    return nx.clustering(graph)\n",
    "\n",
    "def calculate_centrality(graph: nx.Graph, method: str = 'betweenness') -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Calculates centrality measures based on the specified method.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: The NetworkX graph.\n",
    "    - method: The centrality measure to calculate ('betweenness', 'closeness', etc.).\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary mapping node IDs to their centrality values.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If an unsupported centrality method is specified.\n",
    "    \"\"\"\n",
    "    if method == 'betweenness':\n",
    "        return nx.betweenness_centrality(graph)\n",
    "    elif method == 'closeness':\n",
    "        return nx.closeness_centrality(graph)\n",
    "    elif method == 'eigenvector':\n",
    "        try:\n",
    "            return nx.eigenvector_centrality(graph, max_iter=1000)\n",
    "        except nx.PowerIterationFailedConvergence:\n",
    "            print(\"Eigenvector centrality did not converge. Returning empty dictionary.\")\n",
    "            return {}\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported centrality method: {method}\")\n",
    "\n",
    "# 4. Utility Functions for Printing\n",
    "\n",
    "def print_degree_statistics(degrees: Dict[int, int]) -> None:\n",
    "    \"\"\"\n",
    "    Prints statistics about node degrees.\n",
    "\n",
    "    Parameters:\n",
    "    - degrees: Dictionary mapping node IDs to their degree.\n",
    "    \"\"\"\n",
    "    degree_values = list(degrees.values())\n",
    "    print(\"\\n--- Degree Statistics ---\")\n",
    "    print(f\"Total Nodes: {len(degrees)}\")\n",
    "    print(f\"Average Degree: {sum(degree_values)/len(degree_values):.2f}\")\n",
    "    print(f\"Minimum Degree: {min(degree_values)}\")\n",
    "    print(f\"Maximum Degree: {max(degree_values)}\")\n",
    "    print(f\"Median Degree: {sorted(degree_values)[len(degree_values)//2]}\")\n",
    "    print(\"\\nTop 5 Nodes by Degree:\")\n",
    "    top_degree = sorted(degrees.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for node, degree in top_degree:\n",
    "        print(f\"Node {node}: Degree {degree}\")\n",
    "\n",
    "def print_clustering_statistics(clustering_coeffs: Dict[int, float]) -> None:\n",
    "    \"\"\"\n",
    "    Prints statistics about clustering coefficients.\n",
    "\n",
    "    Parameters:\n",
    "    - clustering_coeffs: Dictionary mapping node IDs to their clustering coefficient.\n",
    "    \"\"\"\n",
    "    clustering_values = list(clustering_coeffs.values())\n",
    "    print(\"\\n--- Clustering Coefficient Statistics ---\")\n",
    "    print(f\"Average Clustering Coefficient: {sum(clustering_values)/len(clustering_values):.4f}\")\n",
    "    print(f\"Minimum Clustering Coefficient: {min(clustering_values):.4f}\")\n",
    "    print(f\"Maximum Clustering Coefficient: {max(clustering_values):.4f}\")\n",
    "    print(\"\\nTop 5 Nodes by Clustering Coefficient:\")\n",
    "    top_clustering = sorted(clustering_coeffs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for node, coeff in top_clustering:\n",
    "        print(f\"Node {node}: Clustering Coefficient {coeff:.4f}\")\n",
    "\n",
    "def print_centrality_statistics(centrality: Dict[int, float], method: str) -> None:\n",
    "    \"\"\"\n",
    "    Prints statistics about a centrality measure.\n",
    "\n",
    "    Parameters:\n",
    "    - centrality: Dictionary mapping node IDs to their centrality values.\n",
    "    - method: The centrality measure name.\n",
    "    \"\"\"\n",
    "    if not centrality:\n",
    "        print(f\"\\n--- {method.capitalize()} Centrality Statistics ---\")\n",
    "        print(\"Centrality measure could not be calculated.\")\n",
    "        return\n",
    "\n",
    "    centrality_values = list(centrality.values())\n",
    "    print(f\"\\n--- {method.capitalize()} Centrality Statistics ---\")\n",
    "    print(f\"Average {method.capitalize()} Centrality: {sum(centrality_values)/len(centrality_values):.6f}\")\n",
    "    print(f\"Minimum {method.capitalize()} Centrality: {min(centrality_values):.6f}\")\n",
    "    print(f\"Maximum {method.capitalize()} Centrality: {max(centrality_values):.6f}\")\n",
    "    print(\"\\nTop 5 Nodes by Centrality:\")\n",
    "    top_centrality = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for node, cent in top_centrality:\n",
    "        print(f\"Node {node}: {method.capitalize()} Centrality {cent:.6f}\")\n",
    "\n",
    "def print_circle_statistics(circles: Dict[str, List[int]], graph: nx.Graph) -> None:\n",
    "    \"\"\"\n",
    "    Prints statistics about the circles (communities) in the graph.\n",
    "\n",
    "    Parameters:\n",
    "    - circles: Dictionary mapping circle names to lists of node IDs.\n",
    "    - graph: The NetworkX graph.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Circle (Community) Statistics ---\")\n",
    "    print(f\"Total Circles: {len(circles)}\")\n",
    "    circle_sizes = [len(nodes) for nodes in circles.values()]\n",
    "    print(f\"Average Circle Size: {sum(circle_sizes)/len(circle_sizes):.2f}\")\n",
    "    print(f\"Minimum Circle Size: {min(circle_sizes)}\")\n",
    "    print(f\"Maximum Circle Size: {max(circle_sizes)}\")\n",
    "    \n",
    "    # Find circles with maximum overlapping nodes\n",
    "    node_circle_counts = {}\n",
    "    for circle_nodes in circles.values():\n",
    "        for node in circle_nodes:\n",
    "            node_circle_counts[node] = node_circle_counts.get(node, 0) + 1\n",
    "    overlapping_nodes = {node: count for node, count in node_circle_counts.items() if count > 1}\n",
    "    print(f\"\\nNodes belonging to multiple circles: {len(overlapping_nodes)}\")\n",
    "    if overlapping_nodes:\n",
    "        print(\"Sample of overlapping nodes:\")\n",
    "        sample_overlaps = list(overlapping_nodes.items())[:5]\n",
    "        for node, count in sample_overlaps:\n",
    "            print(f\"Node {node}: {count} circles\")\n",
    "\n",
    "def print_graph_summary(graph: nx.Graph) -> None:\n",
    "    \"\"\"\n",
    "    Prints a summary of the graph.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: The NetworkX graph.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Graph Summary ---\")\n",
    "    print(f\"Number of Nodes: {graph.number_of_nodes()}\")\n",
    "    print(f\"Number of Edges: {graph.number_of_edges()}\")\n",
    "    print(f\"Density: {nx.density(graph):.6f}\")\n",
    "    connected_components = nx.number_connected_components(graph)\n",
    "    print(f\"Number of Connected Components: {connected_components}\")\n",
    "    largest_cc = max(nx.connected_components(graph), key=len)\n",
    "    print(f\"Size of Largest Connected Component: {len(largest_cc)}\")\n",
    "    print(f\"Is the graph connected? {'Yes' if connected_components == 1 else 'No'}\")\n",
    "\n",
    "# 5. Main Function\n",
    "\n",
    "def main(node_id: int):\n",
    "    \"\"\"\n",
    "    Main function to load data, construct the graph, calculate metrics, and print all relevant information.\n",
    "\n",
    "    Parameters:\n",
    "    - node_id: The ID of the ego node.\n",
    "    \"\"\"\n",
    "    # Define file paths based on node_id\n",
    "    edges_file = f\"facebook/{node_id}.edges\"\n",
    "    circles_file = f\"facebook/{node_id}.circles\"\n",
    "    features_file = f\"facebook/{node_id}.feat\"\n",
    "    ego_features_file = f\"facebook/{node_id}.egofeat\"\n",
    "    feature_names_file = f\"facebook/{node_id}.featnames\"\n",
    "\n",
    "    print(f\"Loading data for Node ID: {node_id}\\n\")\n",
    "\n",
    "    # Load data\n",
    "    edges = load_edges(edges_file)\n",
    "    circles = load_circles(circles_file)\n",
    "    features = load_features(features_file)\n",
    "    ego_features = load_ego_features(ego_features_file)\n",
    "    feature_names = load_feature_names(feature_names_file)\n",
    "\n",
    "    # Construct graph\n",
    "    G = construct_graph(edges, ego_node=node_id)\n",
    "    add_circles_to_graph(G, circles)\n",
    "\n",
    "    # Print graph summary\n",
    "    print_graph_summary(G)\n",
    "\n",
    "    # Calculate network metrics\n",
    "    degrees = calculate_degree(G)\n",
    "    clustering_coeffs = calculate_clustering_coefficient(G)\n",
    "    betweenness = calculate_centrality(G, method='betweenness')\n",
    "    closeness = calculate_centrality(G, method='closeness')\n",
    "    eigenvector = calculate_centrality(G, method='eigenvector')\n",
    "\n",
    "    # Print degree statistics\n",
    "    print_degree_statistics(degrees)\n",
    "\n",
    "    # Print clustering coefficient statistics\n",
    "    print_clustering_statistics(clustering_coeffs)\n",
    "\n",
    "    # Print centrality statistics\n",
    "    print_centrality_statistics(betweenness, 'betweenness')\n",
    "    print_centrality_statistics(closeness, 'closeness')\n",
    "    print_centrality_statistics(eigenvector, 'eigenvector')\n",
    "\n",
    "    # Print circle statistics\n",
    "    print_circle_statistics(circles, G)\n",
    "\n",
    "    # Optional: Print ego node information\n",
    "    print(\"\\n--- Ego Node Information ---\")\n",
    "    print(f\"Ego Node ID: {node_id}\")\n",
    "    if 'circles' in G.nodes[node_id]:\n",
    "        print(f\"Circles: {', '.join(G.nodes[node_id]['circles'])}\")\n",
    "    else:\n",
    "        print(\"Circles: None\")\n",
    "    # If you want to print ego features\n",
    "    # print(f\"Ego Features: {ego_features}\")\n",
    "    # print(f\"Feature Names: {feature_names}\")\n",
    "\n",
    "    # Optional: Identify bridges in the graph\n",
    "    bridges = list(nx.bridges(G))\n",
    "    print(f\"\\nNumber of Bridges in the Graph: {len(bridges)}\")\n",
    "    print(\"Sample Bridges:\")\n",
    "    for bridge in bridges[:5]:\n",
    "        print(f\"{bridge[0]} - {bridge[1]}\")\n",
    "\n",
    "    # Optional: Print top bridges based on betweenness centrality\n",
    "    print(\"\\n--- Top 5 Bridges by Betweenness Centrality ---\")\n",
    "    bridge_betweenness = {bridge: betweenness[bridge[0]] + betweenness[bridge[1]] for bridge in bridges}\n",
    "    top_bridges = sorted(bridge_betweenness.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for bridge, cent in top_bridges:\n",
    "        print(f\"{bridge[0]} - {bridge[1]}: Betweenness Centrality {cent:.6f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    node_id = 0  # Replace with desired node ID\n",
    "    main(node_id)\n"
   ],
   "id": "fd1b93b88c37a66f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for Node ID: 0\n",
      "\n",
      "\n",
      "--- Graph Summary ---\n",
      "Number of Nodes: 343\n",
      "Number of Edges: 2519\n",
      "Density: 0.042948\n",
      "Number of Connected Components: 15\n",
      "Size of Largest Connected Component: 324\n",
      "Is the graph connected? No\n",
      "\n",
      "--- Degree Statistics ---\n",
      "Total Nodes: 343\n",
      "Average Degree: 14.69\n",
      "Minimum Degree: 0\n",
      "Maximum Degree: 77\n",
      "Median Degree: 10\n",
      "\n",
      "Top 5 Nodes by Degree:\n",
      "Node 56: Degree 77\n",
      "Node 67: Degree 75\n",
      "Node 271: Degree 72\n",
      "Node 322: Degree 71\n",
      "Node 25: Degree 68\n",
      "\n",
      "--- Clustering Coefficient Statistics ---\n",
      "Average Clustering Coefficient: 0.4934\n",
      "Minimum Clustering Coefficient: 0.0000\n",
      "Maximum Clustering Coefficient: 1.0000\n",
      "\n",
      "Top 5 Nodes by Clustering Coefficient:\n",
      "Node 46: Clustering Coefficient 1.0000\n",
      "Node 135: Clustering Coefficient 1.0000\n",
      "Node 63: Clustering Coefficient 1.0000\n",
      "Node 76: Clustering Coefficient 1.0000\n",
      "Node 273: Clustering Coefficient 1.0000\n",
      "\n",
      "--- Betweenness Centrality Statistics ---\n",
      "Average Betweenness Centrality: 0.007202\n",
      "Minimum Betweenness Centrality: 0.000000\n",
      "Maximum Betweenness Centrality: 0.250516\n",
      "\n",
      "Top 5 Nodes by Centrality:\n",
      "Node 277: Betweenness Centrality 0.250516\n",
      "Node 175: Betweenness Centrality 0.231874\n",
      "Node 19: Betweenness Centrality 0.168522\n",
      "Node 23: Betweenness Centrality 0.122708\n",
      "Node 25: Betweenness Centrality 0.080437\n",
      "\n",
      "--- Closeness Centrality Statistics ---\n",
      "Average Closeness Centrality: 0.250380\n",
      "Minimum Closeness Centrality: 0.000000\n",
      "Maximum Closeness Centrality: 0.401389\n",
      "\n",
      "Top 5 Nodes by Centrality:\n",
      "Node 277: Closeness Centrality 0.401389\n",
      "Node 25: Closeness Centrality 0.369764\n",
      "Node 322: Closeness Centrality 0.365336\n",
      "Node 67: Closeness Centrality 0.361440\n",
      "Node 119: Closeness Centrality 0.360160\n",
      "\n",
      "--- Eigenvector Centrality Statistics ---\n",
      "Average Eigenvector Centrality: 0.029282\n",
      "Minimum Eigenvector Centrality: 0.000000\n",
      "Maximum Eigenvector Centrality: 0.198145\n",
      "\n",
      "Top 5 Nodes by Centrality:\n",
      "Node 56: Eigenvector Centrality 0.198145\n",
      "Node 67: Eigenvector Centrality 0.197438\n",
      "Node 271: Eigenvector Centrality 0.193678\n",
      "Node 26: Eigenvector Centrality 0.186401\n",
      "Node 252: Eigenvector Centrality 0.177161\n",
      "\n",
      "--- Circle (Community) Statistics ---\n",
      "Total Circles: 24\n",
      "Average Circle Size: 13.54\n",
      "Minimum Circle Size: 1\n",
      "Maximum Circle Size: 133\n",
      "\n",
      "Nodes belonging to multiple circles: 39\n",
      "Sample of overlapping nodes:\n",
      "Node 54: 2 circles\n",
      "Node 298: 2 circles\n",
      "Node 97: 2 circles\n",
      "Node 183: 2 circles\n",
      "Node 173: 2 circles\n",
      "\n",
      "--- Ego Node Information ---\n",
      "Ego Node ID: 0\n",
      "Circles: None\n",
      "\n",
      "Number of Bridges in the Graph: 31\n",
      "Sample Bridges:\n",
      "280 - 153\n",
      "133 - 183\n",
      "239 - 234\n",
      "23 - 267\n",
      "339 - 152\n",
      "\n",
      "--- Top 5 Bridges by Betweenness Centrality ---\n",
      "19 - 138: Betweenness Centrality 0.168522\n",
      "23 - 267: Betweenness Centrality 0.122708\n",
      "339 - 152: Betweenness Centrality 0.110146\n",
      "115 - 192: Betweenness Centrality 0.069920\n",
      "230 - 70: Betweenness Centrality 0.045132\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "60a315e5b29541d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
